import { ChatOpenAI } from "langchain/chat_models/openai";
import { LLMSingleActionAgent } from "langchain/agents";
import { LLMChain } from "langchain/chains";
import { AgentExecutor } from "langchain/agents";
import { PULL_REQUEST_ROLE } from "../prompts/pull_request";
import dotenv from "dotenv";
import { CreatePRSummaryTool, CreateReviewCommentTool } from "../tools/pr";
import { MessageContent } from "langchain/schema";
import { ChatPromptTemplate, SystemMessagePromptTemplate } from "langchain/prompts";
import { BaseOutputParser } from "langchain/schema/output_parser";
import { AgentAction, AgentFinish } from "langchain/schema";
dotenv.config();

const tools = [
  new CreatePRSummaryTool(),
  // new CreateReviewCommentTool(process.env.GITHUB_TOKEN as string)
];

// æ·»åŠ è‡ªå®šä¹‰è¾“å‡ºè§£æå™¨
class CustomJsonOutputParser extends BaseOutputParser<AgentAction | AgentFinish> {
  lc_namespace = ["custom", "json"];
  
  getFormatInstructions(): string {
    return `
      è¾“å…¥æ ¼å¼å¿…é¡»æ˜¯åŒ…å«ä»¥ä¸‹å­—æ®µçš„å¯¹è±¡ï¼š
      - user_name: GitHub ç”¨æˆ·å
      - repo_name: ä»“åº“åç§°
      - pull_number: PR ç¼–å·
      - summary: åŒ…å« walkthrough å’Œ changes çš„å¯¹è±¡
    `;
  }

  async parse(text: string): Promise<AgentAction | AgentFinish> {
    console.log("ğŸš€ ~ CustomJsonOutputParser ~ parse ~ text:", text);
    try {
      const cleanedText = text.replace(/```json\n|\n```/g, '').trim();
      console.log("ğŸš€ ~ CustomJsonOutputParser ~ parse ~ cleanedText:", typeof cleanedText, cleanedText)
      const parsed = JSON.parse(cleanedText);
      console.log("ğŸš€ ~ CustomJsonOutputParser ~ parse ~ parsed:", typeof parsed, parsed)
      
      if (parsed.summary) {
        return {
          tool: "create_pr_summary",
          toolInput: parsed.summary,
          log: text
        } as AgentAction;
      }
      
      // if (parsed.comments) {
      //   return {
      //     tool: "create_review_comment",
      //     toolInput: parsed.comments,
      //     log: text
      //   } as AgentAction;
      // }

      throw new Error("è¾“å‡ºæ ¼å¼ä¸ç¬¦åˆè¦æ±‚");
    } catch (e) {
      console.error("è§£æå¤±è´¥:", e);
      throw e;
    }
  }
}

/**
//  * åˆ†æä»£ç å˜æ›´å¹¶ç”Ÿæˆå®¡æŸ¥è¯„è®ºã€‚
 * @param {string} repo_name - ä»“åº“åç§°
 * @param {string} pull_number - PRç¼–å·
 * @param {string} title - PRæ ‡é¢˜
 * @param {string} description - PRæè¿°
 * @param {string} combinedDiff - GitHubçš„combinedDiffå­—ç¬¦ä¸²ï¼Œæè¿°äº†ä»£ç çš„å˜æ›´ã€‚
 * @returns {Promise<MessageContent>} - è¿”å›ç”Ÿæˆçš„å®¡æŸ¥è¯„è®ºã€‚
 */
export async function analyzeCodeChange(
  repo_name: string,
  pull_number: string,
  title: string,
  description: string,
  combinedDiff: string
): Promise<MessageContent> {
  const llm = new ChatOpenAI({
    configuration: {
      apiKey: process.env.OPENAI_API_KEY,
      baseURL: process.env.OPENAI_API_BASE,
    },
    modelName: "deepseek-ai/DeepSeek-V2.5",
    temperature: 0.7,
  });

  // åˆ›å»º LLM Chain
  const llmChain = new LLMChain({
    llm,
    prompt: ChatPromptTemplate.fromMessages([
      SystemMessagePromptTemplate.fromTemplate(
        PULL_REQUEST_ROLE(repo_name, pull_number, title, description)
      )
    ])
  });

  // ä½¿ç”¨è‡ªå®šä¹‰ Agent
  const agent = new LLMSingleActionAgent({
    llmChain,
    outputParser: new CustomJsonOutputParser(),
    stop: ["\nObservation:"]
  });

  const executor = new AgentExecutor({
    agent,
    tools,
    verbose: true
  });

  const result = await executor.call({
    input: `
      ### PR Title
      ${title}
      ### PR Description 
      ${description}
      ### File Diff
      ${combinedDiff}
    `,
    chat_history: []
  });

  return result.output;
}
